{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":365400,"sourceType":"datasetVersion","datasetId":159484}],"dockerImageVersionId":30085,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### For working with any Machine learning models in python, it will be easier to work with numpy arrays. We can save each subject's numpy arrays inside a structured pickle object.","metadata":{}},{"cell_type":"code","source":"!pip install --verbose --no-cache-dir torch-scatter\n!pip install --verbose --no-cache-dir torch-sparse\n!pip install --verbose --no-cache-dir torch-cluster\n!pip install --verbose --no-cache-dir torch-spline-conv (optional)\n!pip install torch-geometric\n!pip install eeg-positions","metadata":{"execution":{"iopub.status.busy":"2021-05-21T06:43:22.176155Z","iopub.execute_input":"2021-05-21T06:43:22.176577Z","iopub.status.idle":"2021-05-21T06:59:09.658128Z","shell.execute_reply.started":"2021-05-21T06:43:22.17653Z","shell.execute_reply":"2021-05-21T06:59:09.657106Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.io import loadmat\nimport numpy as np\nimport pickle\nimport os\nimport torch\nfrom torch import optim, linalg\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Function\nfrom torch_geometric.nn import SGConv, global_add_pool\nfrom torch_scatter import scatter_add\n#from torch.utils.data import Dataset,DataLoader\nfrom torch_geometric.data import Data, DataLoader\nfrom tqdm import tqdm\nfrom pprint import pprint\nfrom eeg_positions import (\n    get_alias_mapping,\n    get_available_elec_names,\n    get_elec_coords,\n    plot_coords,\n)\nimport time\nimport copy\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:52.043228Z","iopub.execute_input":"2021-05-21T07:12:52.043674Z","iopub.status.idle":"2021-05-21T07:12:56.569917Z","shell.execute_reply.started":"2021-05-21T07:12:52.043583Z","shell.execute_reply":"2021-05-21T07:12:56.569009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The sampling frequency is 128 Hz. So, suppose on a particular day, if say the subject has recorded EEG data for 40 minutes. Then total number of rows in the array will 128x60x40. As mentioned by @inancigdem, for each subject, and during every day, first 10 minutes of data corresponds to 'focussed', next 10 minutes to 'unfocussed', and the remaining to 'drowsed' state. So, I have sliced each individual array going by that information (i.e. slicing till row number 128x10x60 for 'focussed', from 128x10x60 to 128x20x60 for 'unfocussed', and from 128x20x60 till last row for 'drowsed).","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.571379Z","iopub.execute_input":"2021-05-21T07:12:56.571656Z","iopub.status.idle":"2021-05-21T07:12:56.579615Z","shell.execute_reply.started":"2021-05-21T07:12:56.571629Z","shell.execute_reply":"2021-05-21T07:12:56.578951Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fs = 128 \nn_subjects = 5\nmkpt1 = int(fs*10*60)\nmkpt2 = int(fs*20*60)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.580549Z","iopub.execute_input":"2021-05-21T07:12:56.580894Z","iopub.status.idle":"2021-05-21T07:12:56.591281Z","shell.execute_reply.started":"2021-05-21T07:12:56.580853Z","shell.execute_reply":"2021-05-21T07:12:56.590634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Below cell is not really important. I didn't want to manually write the relevant file names for each subject. So, I did the following. It based on what the data contributor has mentioned in an comment. There are 5 subjects, and they have recorded data on 7 separate days (except for subject-5 who has only done that for 6 days). I have segregated each day's data as a trial. Out of these 7, first 2 were used for getting the subject to familiarise with the process. That is why I have only considered the last 5 trials of each subject as training data.","metadata":{}},{"cell_type":"code","source":"subject_map = {}\nfor s in range(1, n_subjects+1):\n    a =  int(7*(s-1)) + 3\n    if s!=5:\n        b = a + 5\n    else:\n        b = a + 4\n    subject_map[s] = [i for i in range(a, b)]\nprint(subject_map)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.592386Z","iopub.execute_input":"2021-05-21T07:12:56.592989Z","iopub.status.idle":"2021-05-21T07:12:56.605135Z","shell.execute_reply.started":"2021-05-21T07:12:56.592959Z","shell.execute_reply":"2021-05-21T07:12:56.604379Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"channels = ['AF3', 'F7', 'F3', 'FC5', 'T7', 'P7', 'O1', 'O2', 'P8', 'T8', 'FC6', 'F4', 'F8', 'AF4']\nuseful_channels = ['F7','F3','P7','O1','O2','P8','AF4']\nuse_channel_inds = []\nfor c in useful_channels:\n    if c in channels:\n        use_channel_inds.append(channels.index(c))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.609262Z","iopub.execute_input":"2021-05-21T07:12:56.609901Z","iopub.status.idle":"2021-05-21T07:12:56.617661Z","shell.execute_reply.started":"2021-05-21T07:12:56.609859Z","shell.execute_reply":"2021-05-21T07:12:56.616561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"inp_dir = '../input/eeg-data-for-mental-attention-state-detection/EEG Data/' ","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.619079Z","iopub.execute_input":"2021-05-21T07:12:56.619413Z","iopub.status.idle":"2021-05-21T07:12:56.627939Z","shell.execute_reply.started":"2021-05-21T07:12:56.61936Z","shell.execute_reply":"2021-05-21T07:12:56.626987Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Saving the pickle object for each subject","metadata":{}},{"cell_type":"code","source":"print(mkpt1)\nprint(mkpt2)\nmkpt3 = 214540\ninterval = mkpt3 - mkpt2\nfor s in range(1, n_subjects+1):\n    data = {}\n    data['channels'] = useful_channels\n    data['fs'] = fs\n    for i, t in enumerate(subject_map[s]):\n        trial = {}\n        trial_data = loadmat(inp_dir + f'eeg_record{t}.mat')\n        eeg = trial_data['o']['data'][0][0][:, 3:17]\n        eeg = eeg[:, use_channel_inds]\n        \n        trial['focussed'] = eeg[:interval]\n        trial['unfocussed'] = eeg[mkpt1:mkpt1+interval]\n        trial['drowsed'] = eeg[mkpt2:mkpt2+interval]\n        data[f'trial_{i+1}'] = trial\n    with open(f'subject_{s}.pkl', 'wb') as f: \n        pickle.dump(data, f, pickle.HIGHEST_PROTOCOL)\n        ","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:12:56.62937Z","iopub.execute_input":"2021-05-21T07:12:56.629704Z","iopub.status.idle":"2021-05-21T07:13:04.759337Z","shell.execute_reply.started":"2021-05-21T07:12:56.629678Z","shell.execute_reply":"2021-05-21T07:13:04.758351Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Loading the pickle objects","metadata":{}},{"cell_type":"markdown","source":"Suppose I just want the data related to 'focussed' state from trial_1 of subject_1","metadata":{}},{"cell_type":"code","source":"with open('subject_1.pkl', 'rb') as f: \n    data = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:13:04.760927Z","iopub.execute_input":"2021-05-21T07:13:04.761231Z","iopub.status.idle":"2021-05-21T07:13:04.787935Z","shell.execute_reply.started":"2021-05-21T07:13:04.761201Z","shell.execute_reply":"2021-05-21T07:13:04.787136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:13:04.789191Z","iopub.execute_input":"2021-05-21T07:13:04.789504Z","iopub.status.idle":"2021-05-21T07:13:05.017505Z","shell.execute_reply.started":"2021-05-21T07:13:04.78948Z","shell.execute_reply":"2021-05-21T07:13:05.016365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"with open('subject_1.pkl', 'rb') as f: \n    data1 = pickle.load(f)\nwith open('subject_2.pkl', 'rb') as f: \n    data2 = pickle.load(f)\nwith open('subject_3.pkl', 'rb') as f: \n    data3 = pickle.load(f)\nwith open('subject_4.pkl', 'rb') as f: \n    data4 = pickle.load(f)\nwith open('subject_5.pkl', 'rb') as f: \n    data5 = pickle.load(f)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:13:05.01889Z","iopub.execute_input":"2021-05-21T07:13:05.019219Z","iopub.status.idle":"2021-05-21T07:13:05.433934Z","shell.execute_reply.started":"2021-05-21T07:13:05.019188Z","shell.execute_reply":"2021-05-21T07:13:05.433048Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"state_num = {'focussed': 0, 'unfocussed': 1,'drowsed': 2}","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:33:02.863059Z","iopub.execute_input":"2021-05-21T07:33:02.863722Z","iopub.status.idle":"2021-05-21T07:33:02.869419Z","shell.execute_reply.started":"2021-05-21T07:33:02.863668Z","shell.execute_reply":"2021-05-21T07:33:02.868309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def maybe_num_nodes(index, num_nodes=None):\n    return index.max().item() + 1 if num_nodes is None else num_nodes\n\n\ndef add_remaining_self_loops(edge_index,\n                             edge_weight=None,\n                             fill_value=1,\n                             num_nodes=None):\n    #A' = A + I\n    num_nodes = maybe_num_nodes(edge_index, num_nodes)\n    row, col = edge_index\n    mask = row != col\n    #maskは0か1\n    inv_mask = ~mask\n    #[1,1,1,1,...] shape(62,)\n    loop_weight = torch.full(\n        (num_nodes, ),\n        fill_value,\n        dtype=None if edge_weight is None else edge_weight.dtype,\n        device=edge_index.device)\n\n    if edge_weight is not None:\n        #62x62x8 = edge_index.size(1)?\n        assert edge_weight.numel() == edge_index.size(1)\n        #inv_mask = 0 or 1\n        remaining_edge_weight = edge_weight[inv_mask]\n        if remaining_edge_weight.numel() > 0:\n            loop_weight[row[inv_mask]] = remaining_edge_weight\n        edge_weight = torch.cat([edge_weight[mask], loop_weight], dim=0)\n\n    loop_index = torch.arange(0, num_nodes, dtype=row.dtype, device=row.device)\n    loop_index = loop_index.unsqueeze(0).repeat(2, 1)\n    #loop indexを二段階で形成[0,1,2,...,61] shape : (2,62)\n    edge_index = torch.cat([edge_index[:, mask], loop_index], dim=1)\n    #loop indexをtorch.cat()\n\n    return edge_index, edge_weight\n\n\nclass NewSGConv(SGConv):\n    def __init__(self, num_features, num_classes, K=1, cached=False,\n                 bias=True):\n        super(NewSGConv, self).__init__(num_features, num_classes, K=K, cached=cached, bias=bias)\n\n    # allow negative edge weights\n    @staticmethod\n    def norm(edge_index, num_nodes, edge_weight, improved=False, dtype=None):\n        if edge_weight is None:\n            #edge_weight.shape(62x62x8,)\n            #edge_index.shape(2,62x62x8)\n            edge_weight = torch.ones((edge_index.size(1), ),\n                                     dtype=dtype,\n                                     device=edge_index.device)\n\n        fill_value = 1 if not improved else 2\n        edge_index, edge_weight = add_remaining_self_loops(\n            edge_index, edge_weight, fill_value, num_nodes)\n        row, col = edge_index\n        #次数行列Dを作成 サイズ 62 x 62\n        #縦に62 edge_weight.shape:[62,62] row.shape:[1,62]\n        #edge_weight:62x62x8, row:62x62x8\n        deg = scatter_add(torch.abs(edge_weight), row, dim=0, dim_size=num_nodes)\n        deg_inv_sqrt = deg.pow(-0.5)\n        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0\n\n        return edge_index, deg_inv_sqrt[row] * edge_weight * deg_inv_sqrt[col]\n\n    def forward(self, x, edge_index, edge_weight=None):\n        if not self.cached or self.cached_result is None:\n            edge_index, norm = NewSGConv.norm(\n                edge_index, x.size(0), edge_weight, dtype=x.dtype)\n\n            #Wは自動で計算？ Z=SXW\n            for k in range(self.K):\n                #print(f'x.shape : {x.size()}')\n                #print(f'edge_index.shape : {edge_index.size()}')\n                #print(f'norm.shape : {norm.size()}')\n                #print(f'norm.max : {norm.max()}')\n                #print(f'norm.min : {norm.min()}')\n                x = self.propagate(edge_index, x=x, norm=norm)\n            self.cached_result = x\n\n        return self.lin(self.cached_result)\n\n    def message(self, x_j, norm):\n        # x_j: (batch_size*num_nodes*num_nodes, num_features)\n        # norm: (batch_size*num_nodes*num_nodes, )\n        return norm.view(-1, 1) * x_j\n\nclass ReverseLayerF(Function):\n    @staticmethod\n    def forward(ctx, x, alpha):\n        ctx.alpha = alpha\n        return x.view_as(x)\n\n    @staticmethod\n    def backward(ctx, grad_output):\n        output = grad_output.neg() * ctx.alpha\n        return output, None\n\n\nclass SymSimGCNNet(torch.nn.Module):\n    def __init__(self, num_nodes, learn_edge_weight, edge_weight, num_features, num_hiddens, num_classes, K, dropout=0.7, domain_adaptation=\"\"):\n        \"\"\"\n            num_nodes: number of nodes in the graph\n            learn_edge_weight: if True, the edge_weight is learnable\n            edge_weight: initial edge matrix\n            num_features: feature dim for each node/channel\n            num_hiddens: a tuple of hidden dimensions\n            num_classes: number of emotion classes\n            K: number of layers\n            dropout: dropout rate in final linear layer\n            domain_adaptation: RevGrad\n        \"\"\"\n        super(SymSimGCNNet, self).__init__()\n        self.domain_adaptation = domain_adaptation\n        self.num_nodes = num_nodes\n        #下の三角形の座標取得\n        self.xs, self.ys = torch.tril_indices(self.num_nodes, self.num_nodes, offset=0)\n        edge_weight = edge_weight.reshape(self.num_nodes, self.num_nodes)[self.xs, self.ys] # strict lower triangular values\n        self.edge_weight = nn.Parameter(edge_weight, requires_grad=learn_edge_weight)\n        self.dropout = dropout\n        self.conv1 = NewSGConv(num_features=num_features, num_classes=num_hiddens[0], K=K)\n        self.fc = nn.Linear(num_hiddens[0], num_classes)\n        if self.domain_adaptation in [\"RevGrad\"]:\n            self.domain_classifier = nn.Linear(num_hiddens[0], 2)\n\n    def forward(self, data, alpha=0):\n        batch_size = len(data.y)\n        #edge_indexは1batchの何か 8x?\n        x, edge_index = data.x, data.edge_index\n        #print(f'edge_index shape: {edge_index.size()}')\n        edge_weight = torch.zeros((self.num_nodes, self.num_nodes), device=edge_index.device)\n        #下の三角形の値だけ入れてる、上の三角形は0\n        edge_weight[self.xs.to(edge_weight.device), self.ys.to(edge_weight.device)] = self.edge_weight\n        edge_weight = edge_weight + edge_weight.transpose(1,0) - torch.diag(edge_weight.diagonal()) # copy values from lower tri to upper tri\n        #下半分の計算で上の計算もしたことになる\n        #1batchの1直線のテンソル\n        edge_weight = edge_weight.reshape(-1).repeat(batch_size)\n        #print(f\"長さ:{edge_weight.shape}\")\n        #print(f'edge_weight max : {edge_weight.max()}, edge_weight min : {edge_weight.min()}')\n        x = F.relu(self.conv1(x, edge_index, edge_weight))\n        \n        # domain classification\n        domain_output = None\n        if self.domain_adaptation in [\"RevGrad\"]:\n            reverse_x = ReverseLayerF.apply(x, alpha)\n            domain_output = self.domain_classifier(reverse_x)\n        x = global_add_pool(x, data.batch, size=batch_size)\n        x = F.dropout(x, p=self.dropout, training=self.training)\n        x = self.fc(x)\n        return x, domain_output","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:33:02.871677Z","iopub.execute_input":"2021-05-21T07:33:02.871974Z","iopub.status.idle":"2021-05-21T07:33:02.901471Z","shell.execute_reply.started":"2021-05-21T07:33:02.871943Z","shell.execute_reply":"2021-05-21T07:33:02.900816Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#(62,62)の行列を初期化する\nedge_weight = torch.zeros(7,7)\n\ncoords = get_elec_coords(\n    elec_names = useful_channels,\n    drop_landmarks = False,\n    dim = \"3d\",\n)\n\nelectrodes_data = {}\nfor ind, row in coords.iterrows():\n    electrodes_data[str(row.label)] = (row.x,row.y,row.z)\n\nfor i in range(7):\n    for j in range(i+1,7):\n        elec_from = useful_channels[i]\n        elec_to = useful_channels[j]\n\n        from_data = electrodes_data[elec_from]\n        to_data = electrodes_data[elec_to]\n        vec_from = np.array(from_data)\n        vec_to = np.array(to_data)\n        dist = np.linalg.norm(vec_from - vec_to)\n        edge_weight[i, j] = dist\n        edge_weight[j, i] = dist\n\nedge_weight = np.where(edge_weight > 0, 0.065 / edge_weight, edge_weight)\n\nedge_weight = torch.tensor(edge_weight).float()\nprint(type(edge_weight))","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.209504Z","iopub.execute_input":"2021-05-21T07:48:08.209857Z","iopub.status.idle":"2021-05-21T07:48:08.4453Z","shell.execute_reply.started":"2021-05-21T07:48:08.209829Z","shell.execute_reply":"2021-05-21T07:48:08.444602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_dataloader():\n    #まずはdataを作成\n    dataset = []    \n    data_list = [data1, data2, data3, data4, data5]\n    for i in range(5):\n        now_data = data_list[i]\n        for j in range(4):\n            now_ind = j + 1\n            trial_name = 'trial_' + str(now_ind)\n            now_trial = now_data[trial_name]\n            for state, val in now_trial.items():\n                y = torch.tensor([state_num[state]]).long()\n                x = torch.tensor(val).float()\n                x = x.permute(1,0)\n                #print(x.size())\n                data = Data(x=x, edge_index=edge_index, y=y)\n                dataset.append(data)\n    \n    #print(len(dataset))\n    #dataset作成完了、次はtrainとvalでsplitしてdataloaderを作成する\n    train, val = train_test_split(dataset, train_size=0.6)\n    train_iterator = DataLoader(train, shuffle=True, batch_size=4, num_workers=2)\n    val_iterator = DataLoader(val, shuffle=False, batch_size=4, num_workers=2)    \n    \n    data = next(iter(train_iterator))\n    \n    return train_iterator, val_iterator","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.446724Z","iopub.execute_input":"2021-05-21T07:48:08.447049Z","iopub.status.idle":"2021-05-21T07:48:08.454403Z","shell.execute_reply.started":"2021-05-21T07:48:08.447024Z","shell.execute_reply":"2021-05-21T07:48:08.453728Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"row = []\ncol = []\nfor i in range(7):\n    for j in range(7):\n        row.append(i)\n        col.append(j)\n\nrow = np.array(row)\ncol = np.array(col)\n\nrow = torch.tensor(row).unsqueeze(0)\ncol = torch.tensor(col).unsqueeze(0)\n\nedge_index = torch.cat([row, col], dim = 0)\n\nprint(edge_index.size())","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.455213Z","iopub.execute_input":"2021-05-21T07:48:08.455567Z","iopub.status.idle":"2021-05-21T07:48:08.468423Z","shell.execute_reply.started":"2021-05-21T07:48:08.455541Z","shell.execute_reply":"2021-05-21T07:48:08.467561Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def labelize(label):\n    label = label.float()\n    #print(f'label : {label}')\n    label.requires_grad = True\n    tensor = None\n    for i in range(4):\n        if i == 0:\n            pos = label[i].detach().long()\n            _tensor = torch.zeros(1,3)\n            _tensor[0, pos] = 1\n            tensor = _tensor\n        else:\n            pos = label[i].detach().long()\n            _tensor = torch.zeros(1,3)\n            _tensor[0, pos] = 1\n            tensor = torch.cat([tensor,_tensor], dim=0)\n\n    tensor.requires_grad = True\n    return tensor","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.469431Z","iopub.execute_input":"2021-05-21T07:48:08.469698Z","iopub.status.idle":"2021-05-21T07:48:08.48307Z","shell.execute_reply.started":"2021-05-21T07:48:08.469674Z","shell.execute_reply":"2021-05-21T07:48:08.482305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\n\ndef fit_model(edge_weight, edge_index):\n        train_iterator, valid_iterator = get_dataloader()\n\n        len_dataloader = min(len(train_iterator), len(valid_iterator))\n\n        #print(\"dataloader まで作ったお\")\n        #こっからモデル定義\n        \"\"\"\n          num_nodes: number of nodes in the graph\n          learn_edge_weight: if True, the edge_weight is learnable\n          edge_weight: initial edge matrix\n          num_features: feature dim for each node/channel \n          num_hiddens: a tuple of hidden dimensions \n          num_classes: number of emotion classes\n          K: number of layers\n          dropout: dropout rate in final linear layer\n          domain_adaptation: RevGrad\n        \"\"\"\n        \"\"\"\n          train_iterator : batch_size-> 4  \n        \"\"\"\n\n        model = SymSimGCNNet(num_nodes=7, learn_edge_weight=True, edge_weight=edge_weight, num_features=60940, num_hiddens=(10,20), num_classes=3, K=2, dropout=0.7, domain_adaptation=\"RevGrad\")\n        #print(f'model : {model}')\n        #print(f'domain_classifier weight : {model.domain_classifier.weight}')\n\n        for p in model.parameters():\n            p.requires_grad = True\n\n        loss_criterion1 = nn.KLDivLoss(reduction=\"sum\")\n        loss_criterion2 = nn.BCELoss()\n        opt = optim.Adam(model.parameters(), lr=0.001)\n        scheduler = optim.lr_scheduler.StepLR(opt, step_size=2, gamma=0.1)\n        softmax = nn.Softmax(dim=1)\n\n        targets = iter(valid_iterator)\n\n        #print(\"targets!!!!\")\n        all_loss = 0\n\n        for j, data in enumerate(train_iterator):\n\n            if j == len_dataloader:\n                break\n\n            #to device\n            data = data.to(device)\n\n\n            opt.zero_grad()\n            y_pred, domain_output_tr = model(data)\n            y_pred = y_pred / linalg.norm(y_pred)\n          \n            y_pred = softmax(y_pred)\n\n            #data.yを(8,4)に変える\n            y = labelize(data.y)\n            \n            print(y_pred.log().size())\n            print(y.size())\n            loss_tr = F.kl_div(y_pred.log(), y, None, None, 'sum')\n        \n            def calc_domain_loss(domain_output, mode):\n                #domain_outputをsigmoidに通す\n                nlf = nn.Sigmoid()\n                domain_output = nlf(domain_output)\n\n                weight = model.domain_classifier.weight\n                weight = weight.to(device)\n\n                #domain_classifierのparameterと掛け合わせる\n                p = softmax(torch.mm(domain_output, weight))\n\n\n                res = None\n\n                #bceを計算\n                if mode == 'zero': \n                    t = torch.zeros(p.size(0), p.size(1))\n                    t = t.to(device)\n                    res = loss_criterion2(p, t).float()\n                if mode == 'one':\n                    t = torch.ones(p.size(0), p.size(1))\n                    t = t.to(device)\n                    res = loss_criterion2(p, t).float()\n\n                return res\n\n            loss_tr_domain = calc_domain_loss(domain_output_tr, 'zero')\n\n            data_eval = next(targets)\n\n            #to device\n            data_eval = data_eval.to(device)\n\n            _, domain_output_te = model(data_eval)\n\n            loss_te_domain = calc_domain_loss(domain_output_te, 'one')\n\n            #domain classifierからのlossを計算して最適化\n            total_loss = loss_tr + loss_tr_domain + loss_te_domain\n            all_loss += total_loss\n            total_loss.backward()\n            opt.step()\n\n            #opt.step()\n            print(f'Epoch: {j+1} / Lr: {scheduler.get_lr()[0]} / Loss: {total_loss}')\n            #print(opt.param_groups[0])\n            scheduler.step()\n\n        end_time = time.time()\n        models.append(model)\n        #epoch_mins, epoch_secs = (end_time - start_time)//60, round((end_time - start_time)%60)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.484141Z","iopub.execute_input":"2021-05-21T07:48:08.48437Z","iopub.status.idle":"2021-05-21T07:48:08.501029Z","shell.execute_reply.started":"2021-05-21T07:48:08.484347Z","shell.execute_reply":"2021-05-21T07:48:08.500167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"get_dataloader()","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.503269Z","iopub.execute_input":"2021-05-21T07:48:08.503577Z","iopub.status.idle":"2021-05-21T07:48:08.72869Z","shell.execute_reply.started":"2021-05-21T07:48:08.50355Z","shell.execute_reply":"2021-05-21T07:48:08.727792Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fit_model(edge_weight, edge_index)","metadata":{"execution":{"iopub.status.busy":"2021-05-21T07:48:08.731921Z","iopub.execute_input":"2021-05-21T07:48:08.732209Z","iopub.status.idle":"2021-05-21T07:48:11.869266Z","shell.execute_reply.started":"2021-05-21T07:48:08.73218Z","shell.execute_reply":"2021-05-21T07:48:11.867411Z"},"trusted":true},"execution_count":null,"outputs":[]}]}